{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elizavetakotelnikova/ML_projects_course/blob/main/Simpsons_predictions_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xw7YkEefehWo"
      },
      "source": [
        "# Домашнее задание. Классификация изображений\n",
        "\n",
        "Сегодня вам предстоить помочь телекомпании FOX в обработке их контента. Как вы знаете, сериал \"Симпсоны\" идет на телеэкранах более 25 лет, и за это время скопилось очень много видеоматериала. Персоонажи менялись вместе с изменяющимися графическими технологиями, и Гомер Симпсон-2018 не очень похож на Гомера Симпсона-1989. В этом задании вам необходимо классифицировать персонажей, проживающих в Спрингфилде. Думаю, нет смысла представлять каждого из них в отдельности.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X82g2RD8HqYr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oG47vhLxKNln"
      },
      "source": [
        "### Установка зависимостей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWgcwKwCLBfr",
        "outputId": "b1e3c3b8-6fcb-4af3-de3a-fb48f08294cb"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA is available!  Training on GPU ...\n"
          ]
        }
      ],
      "source": [
        "# we will verify that GPU is enabled for this notebook\n",
        "# following should print: CUDA is available!  Training on GPU ...\n",
        "#\n",
        "# if it prints otherwise, then you need to enable GPU:\n",
        "# from Menu > Runtime > Change Runtime Type > Hardware Accelerator > GPU\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXno2OSeLF3e",
        "outputId": "6e716d3a-05ef-432b-f6b3-9a81649be5a9"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9.4.0\n"
          ]
        }
      ],
      "source": [
        "import PIL\n",
        "print(PIL.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xA3o2xC3MlMI",
        "outputId": "1c90e8cd-c556-4201-f23c-1238b1fefdfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n",
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.flush_and_unmount()\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxZ5llqziJ8k"
      },
      "outputs": [],
      "source": [
        "!unzip -q /content/gdrive/MyDrive/journey-springfield.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2dg3IHMMo-s",
        "outputId": "4309d8bf-0add-4005-d0bf-bcabfd326196"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "simpsons_dataset\n"
          ]
        }
      ],
      "source": [
        "!ls train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvWhlkiRMxih",
        "outputId": "eff73768-7724-4760-a8f0-7c094167c5d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Jan  4 17:23:45 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8               9W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!nvidia-smi\n",
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD_8gK6PmgXk"
      },
      "source": [
        "В нашем тесте будет 990 картнок, для которых вам будет необходимо предсказать класс."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naD6xsZzMxrC"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "\n",
        "from torchvision import transforms\n",
        "from multiprocessing.pool import ThreadPool\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "\n",
        "from matplotlib import colors, pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# в sklearn не все гладко, чтобы в colab удобно выводить картинки\n",
        "# мы будем игнорировать warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTdzMtgJP15N"
      },
      "outputs": [],
      "source": [
        "# разные режимы датасета\n",
        "DATA_MODES = ['train', 'val', 'test']\n",
        "# все изображения будут масштабированы к размеру 224x224 px\n",
        "RESCALE_SIZE = 224\n",
        "# работаем на видеокарте\n",
        "DEVICE = torch.device(\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYFeKUzfy572"
      },
      "source": [
        "https://jhui.github.io/2018/02/09/PyTorch-Data-loading-preprocess_torchvision/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ecnkB2xK1aE"
      },
      "source": [
        "Ниже мы исспользуем враппер над датасетом для удобной работы. Вам стоит понимать, что происходит с LabelEncoder и  с torch.Transformation.\n",
        "\n",
        "ToTensor конвертирует  PIL Image с параметрами в диапазоне [0, 255] (как все пиксели) в FloatTensor размера (C x H x W) [0,1] , затем производится масштабирование:\n",
        "$input = \\frac{input - \\mu}{\\text{standard deviation}} $, <br>       константы - средние и дисперсии по каналам на основе ImageNet\n",
        "\n",
        "\n",
        "Стоит также отметить, что мы переопределяем метод __getitem__ для удобства работы с данной структурой данных.\n",
        " Также используется LabelEncoder для преобразования строковых меток классов в id и обратно. В описании датасета указано, что картинки разного размера, так как брались напрямую с видео, поэтому следуем привести их к одному размер (это делает метод  _prepare_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cj32U5iTQUe4"
      },
      "outputs": [],
      "source": [
        "class SimpsonsDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Датасет с картинками, который паралельно подгружает их из папок\n",
        "    производит скалирование и превращение в торчевые тензоры\n",
        "    \"\"\"\n",
        "    def __init__(self, files, mode):\n",
        "        super().__init__()\n",
        "        # список файлов для загрузки\n",
        "        self.files = sorted(files)\n",
        "        # режим работы\n",
        "        self.mode = mode\n",
        "\n",
        "        if self.mode not in DATA_MODES:\n",
        "            print(f\"{self.mode} is not correct; correct modes: {DATA_MODES}\")\n",
        "            raise NameError\n",
        "\n",
        "        self.len_ = len(self.files)\n",
        "\n",
        "        self.label_encoder = LabelEncoder()\n",
        "\n",
        "        if self.mode != 'test':\n",
        "            self.labels = [path.parent.name for path in self.files]\n",
        "            self.label_encoder.fit(self.labels)\n",
        "\n",
        "            with open('label_encoder.pkl', 'wb') as le_dump_file:\n",
        "                  pickle.dump(self.label_encoder, le_dump_file)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len_\n",
        "\n",
        "    def load_sample(self, file):\n",
        "        image = Image.open(file)\n",
        "        image.load()\n",
        "        return image\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # для преобразования изображений в тензоры PyTorch и нормализации входа\n",
        "        transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "        x = self.load_sample(self.files[index])\n",
        "        x = self._prepare_sample(x)\n",
        "        x = np.array(x / 255, dtype='float32')\n",
        "        x = transform(x)\n",
        "        if self.mode == 'test':\n",
        "            return x\n",
        "        else:\n",
        "            label = self.labels[index]\n",
        "            label_id = self.label_encoder.transform([label])\n",
        "            y = label_id.item()\n",
        "            return x, y\n",
        "\n",
        "    def _prepare_sample(self, image):\n",
        "        image = image.resize((RESCALE_SIZE, RESCALE_SIZE))\n",
        "        return np.array(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_odtTEzcaWH"
      },
      "outputs": [],
      "source": [
        "def imshow(inp, title=None, plt_ax=plt, default=False):\n",
        "    \"\"\"Imshow для тензоров\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt_ax.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt_ax.set_title(title)\n",
        "    plt_ax.grid(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXyvJfT5jY-A"
      },
      "outputs": [],
      "source": [
        "#определим директории с тренировочными и тестовыми файлами\n",
        "TRAIN_DIR = Path('./train/')\n",
        "TEST_DIR = Path('./testset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUhzOq1zRJil"
      },
      "outputs": [],
      "source": [
        "train_val_files = sorted(list(TRAIN_DIR.rglob('*.jpg')))\n",
        "test_files = sorted(list(TEST_DIR.rglob('*.jpg')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmPhhKKlRyCF"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_val_labels = [path.parent.name for path in train_val_files]\n",
        "train_files, val_files = train_test_split(train_val_files, test_size=0.25, \\\n",
        "                                          stratify=train_val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAimOLjSQGTh"
      },
      "outputs": [],
      "source": [
        "val_dataset = SimpsonsDataset(val_files, mode='val')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMgIbm6hRwdQ"
      },
      "outputs": [],
      "source": [
        "# uncomment if you have problem with pillow\n",
        "# def register_extension(id, extension): Image.EXTENSION[extension.lower()] = id.upper()\n",
        "# Image.register_extension = register_extension\n",
        "# def register_extensions(id, extensions):\n",
        "#     for extension in extensions: register_extension(id, extension)\n",
        "# Image.register_extensions = register_extensions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmKSdyv1b7PD"
      },
      "source": [
        "Давайте посмотрим на наших героев внутри датасета."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltitWp3lXAZt"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(nrows=3, ncols=3,figsize=(8, 8), \\\n",
        "                        sharey=True, sharex=True)\n",
        "for fig_x in ax.flatten():\n",
        "    random_characters = int(np.random.uniform(0,1000))\n",
        "    im_val, label = val_dataset[random_characters]\n",
        "    img_label = \" \".join(map(lambda x: x.capitalize(),\\\n",
        "                val_dataset.label_encoder.inverse_transform([label])[0].split('_')))\n",
        "    imshow(im_val.data.cpu(), \\\n",
        "          title=img_label,plt_ax=fig_x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpN9lSi4QVGt"
      },
      "source": [
        "Можете добавить ваши любимые сцены и классифицировать их. (веселые результаты можно кидать в чат)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6YcZk8vQR47"
      },
      "source": [
        "### Построение нейросети\n",
        "\n",
        "Запустить данную сеть будет вашим мини-заданием на первую неделю, чтобы было проще участвовать в соревновании.\n",
        "\n",
        "Данная архитектура будет очень простой и нужна для того, чтобы установить базовое понимание и получить простенький сабмит на Kaggle\n",
        "\n",
        "<!-- Здесь вам предлагается дописать сверточную сеть глубины 4/5.  -->\n",
        "\n",
        "*Описание слоев*:\n",
        "\n",
        "\n",
        "\n",
        "1. размерность входа: 3x224x224\n",
        "2.размерности после слоя:  8x111x111\n",
        "3. 16x54x54\n",
        "4. 32x26x26\n",
        "5. 64x12x12\n",
        "6. выход: 96x5x5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PJcWAhuji-i"
      },
      "outputs": [],
      "source": [
        "# Очень простая сеть\n",
        "class SimpleCnn(nn.Module):\n",
        "\n",
        "    def __init__(self, n_classes):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=96, kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "\n",
        "        self.out = nn.Linear(96 * 5 * 5, n_classes)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        logits = self.out(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2mk7MNtcUhJ"
      },
      "outputs": [],
      "source": [
        "def fit_epoch(model, train_loader, criterion, optimizer):\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    processed_data = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs = inputs.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        preds = torch.argmax(outputs, 1)\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "        processed_data += inputs.size(0)\n",
        "\n",
        "    train_loss = running_loss / processed_data\n",
        "    train_acc = running_corrects.cpu().numpy() / processed_data\n",
        "    return train_loss, train_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_CD9--hcUjs"
      },
      "outputs": [],
      "source": [
        "def eval_epoch(model, val_loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    processed_size = 0\n",
        "\n",
        "    for inputs, labels in val_loader:\n",
        "        inputs = inputs.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "\n",
        "        with torch.set_grad_enabled(False):\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            preds = torch.argmax(outputs, 1)\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "        processed_size += inputs.size(0)\n",
        "    val_loss = running_loss / processed_size\n",
        "    val_acc = running_corrects.double() / processed_size\n",
        "    return val_loss, val_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NaxYIwB3cUmX"
      },
      "outputs": [],
      "source": [
        "def train(train_files, val_files, model, epochs, batch_size):\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    history = []\n",
        "    log_template = \"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \\\n",
        "    val_loss {v_loss:0.4f} train_acc {t_acc:0.4f} val_acc {v_acc:0.4f}\"\n",
        "\n",
        "    with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:\n",
        "        opt = torch.optim.Adam(model.parameters())\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            train_loss, train_acc = fit_epoch(model, train_loader, criterion, opt)\n",
        "            print(\"loss\", train_loss)\n",
        "\n",
        "            val_loss, val_acc = eval_epoch(model, val_loader, criterion)\n",
        "            history.append((train_loss, train_acc, val_loss, val_acc))\n",
        "\n",
        "            pbar_outer.update(1)\n",
        "            tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss,\\\n",
        "                                           v_loss=val_loss, t_acc=train_acc, v_acc=val_acc))\n",
        "\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6G7qbYqcUpL"
      },
      "outputs": [],
      "source": [
        "def predict(model, test_loader):\n",
        "    with torch.no_grad():\n",
        "        logits = []\n",
        "\n",
        "        for inputs in test_loader:\n",
        "            inputs = inputs.to(DEVICE)\n",
        "            model.eval()\n",
        "            outputs = model(inputs).cpu()\n",
        "            logits.append(outputs)\n",
        "\n",
        "    probs = nn.functional.softmax(torch.cat(logits), dim=-1).numpy()\n",
        "    return probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzwhB4K3dQOC"
      },
      "outputs": [],
      "source": [
        "n_classes = len(np.unique(train_val_labels))\n",
        "simple_cnn = SimpleCnn(n_classes).to(DEVICE)\n",
        "print(\"we will classify :{}\".format(n_classes))\n",
        "print(simple_cnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bo3UND5RdgVg"
      },
      "source": [
        "Запустим обучение сети."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDkcxZ1kfD4a"
      },
      "outputs": [],
      "source": [
        "if val_dataset is None:\n",
        "    val_dataset = SimpsonsDataset(val_files, mode='val')\n",
        "\n",
        "train_dataset = SimpsonsDataset(train_files, mode='train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDXoR8PIdfLD"
      },
      "outputs": [],
      "source": [
        "history = train(train_dataset, val_dataset, model=simple_cnn, epochs=2, batch_size=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qMAdL_BduXZ"
      },
      "source": [
        "Построим кривые обучения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ryD_9yFdfNr"
      },
      "outputs": [],
      "source": [
        "loss, acc, val_loss, val_acc = zip(*history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpQDWGkfdfQ5"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 9))\n",
        "plt.plot(loss, label=\"train_loss\")\n",
        "plt.plot(val_loss, label=\"val_loss\")\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gr9lRCJNNDfD"
      },
      "source": [
        "### Ну и что теперь со всем этим делать?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSe0nQ-dJ8uy"
      },
      "source": [
        "![alt text](https://www.indiewire.com/wp-content/uploads/2014/08/the-simpsons.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5k0UGeTNaQX"
      },
      "source": [
        "Хорошо бы понять, как сделать сабмит.\n",
        "У нас есть сеть и методы eval у нее, которые позволяют перевести сеть в режим предсказания. Стоит понимать, что у нашей модели на последнем слое стоит softmax, которые позволяет получить вектор вероятностей  того, что объект относится к тому или иному классу. Давайте воспользуемся этим."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8PlF6o0N9O1"
      },
      "outputs": [],
      "source": [
        "def predict_one_sample(model, inputs, device=DEVICE):\n",
        "    \"\"\"Предсказание, для одной картинки\"\"\"\n",
        "    with torch.no_grad():\n",
        "        inputs = inputs.to(device)\n",
        "        model.eval()\n",
        "        logit = model(inputs).cpu()\n",
        "        probs = torch.nn.functional.softmax(logit, dim=-1).numpy()\n",
        "    return probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pY_OoLoVO_9V"
      },
      "outputs": [],
      "source": [
        "random_characters = int(np.random.uniform(0,1000))\n",
        "ex_img, true_label = val_dataset[random_characters]\n",
        "probs_im = predict_one_sample(simple_cnn, ex_img.unsqueeze(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caivVFeAN9SY"
      },
      "outputs": [],
      "source": [
        "idxs = list(map(int, np.random.uniform(0,1000, 20)))\n",
        "imgs = [val_dataset[id][0].unsqueeze(0) for id in idxs]\n",
        "\n",
        "probs_ims = predict(simple_cnn, imgs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-0pRdHnQQKM"
      },
      "outputs": [],
      "source": [
        "label_encoder = pickle.load(open(\"label_encoder.pkl\", 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNMFc7sfQh1a"
      },
      "outputs": [],
      "source": [
        "y_pred = np.argmax(probs_ims,-1)\n",
        "\n",
        "actual_labels = [val_dataset[id][1] for id in idxs]\n",
        "\n",
        "preds_class = [label_encoder.classes_[i] for i in y_pred]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVePL0-BKHrF"
      },
      "source": [
        "Обратите внимание, что метрика, которую необходимо оптимизировать в конкурсе --- f1-score. Вычислим целевую метрику на валидационной выборке."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_h-9dDWsKGU-"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1 = f1_score(actual_labels, y_pred, average='micro')\n",
        "\n",
        "print(\"F1-оценка:\", f1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxB9pfPfdCHr"
      },
      "source": [
        "Сделаем классную визуализацию,  чтобы посмотреть насколько сеть уверена в своих ответах. Можете исспользовать это, чтобы отлаживать правильность вывода."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVjq4EC5ZZE7"
      },
      "outputs": [],
      "source": [
        "import matplotlib.patches as patches\n",
        "from matplotlib.font_manager import FontProperties\n",
        "\n",
        "fig, ax = plt.subplots(nrows=3, ncols=3,figsize=(12, 12), \\\n",
        "                        sharey=True, sharex=True)\n",
        "for fig_x in ax.flatten():\n",
        "    random_characters = int(np.random.uniform(0,1000))\n",
        "    im_val, label = val_dataset[random_characters]\n",
        "    img_label = \" \".join(map(lambda x: x.capitalize(),\\\n",
        "                val_dataset.label_encoder.inverse_transform([label])[0].split('_')))\n",
        "\n",
        "\n",
        "\n",
        "    imshow(im_val.data.cpu(), \\\n",
        "          title=img_label,plt_ax=fig_x)\n",
        "\n",
        "    actual_text = \"Actual : {}\".format(img_label)\n",
        "\n",
        "    fig_x.add_patch(patches.Rectangle((0, 53),86,35,color='white'))\n",
        "    font0 = FontProperties()\n",
        "    font = font0.copy()\n",
        "    font.set_family(\"fantasy\")\n",
        "    prob_pred = predict_one_sample(simple_cnn, im_val.unsqueeze(0))\n",
        "    predicted_proba = np.max(prob_pred)*100\n",
        "    y_pred = np.argmax(prob_pred)\n",
        "\n",
        "    predicted_label = label_encoder.classes_[y_pred]\n",
        "    predicted_label = predicted_label[:len(predicted_label)//2] + '\\n' + predicted_label[len(predicted_label)//2:]\n",
        "    predicted_text = \"{} : {:.0f}%\".format(predicted_label,predicted_proba)\n",
        "\n",
        "    fig_x.text(1, 59, predicted_text , horizontalalignment='left', fontproperties=font,\n",
        "                    verticalalignment='top',fontsize=8, color='black',fontweight='bold')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hO9OLOMqIXRV"
      },
      "source": [
        "Попробуйте найти те классы, которые сеть не смогла расспознать. Изучите данную проблему, это понадобится в дальнейшем."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEWTL6jgdh7L"
      },
      "source": [
        "### Submit на Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrjQ6cxHIGtk"
      },
      "source": [
        "![alt text](https://i.redd.it/nuaphfioz0211.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UTbU0Zbc6Hb"
      },
      "outputs": [],
      "source": [
        "test_dataset = SimpsonsDataset(test_files, mode=\"test\")\n",
        "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=64)\n",
        "probs = predict(simple_cnn, test_loader)\n",
        "\n",
        "\n",
        "preds = label_encoder.inverse_transform(np.argmax(probs, axis=1))\n",
        "test_filenames = [path.name for path in test_dataset.files]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rTtbV1teD2k"
      },
      "outputs": [],
      "source": [
        "! ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yw0zZ-Hdd89s"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "my_submit = pd.read_csv(\"/content/sample_submission.csv\")\n",
        "my_submit = pd.DataFrame({'Id': test_filenames, 'Expected': preds})\n",
        "my_submit.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5rdlyMKtiYe2"
      },
      "outputs": [],
      "source": [
        "my_submit.to_csv('simple_cnn_baseline.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3M9SQZ7MuUq"
      },
      "source": [
        "## Приключение?\n",
        "\n",
        "А теперь самое интересное, мы сделали простенькую сверточную сеть и смогли отправить сабмит, но получившийся скор нас явно не устраивает. Надо с этим что-то сделать.\n",
        "\n",
        "Несколько срочныйх улучшейни для нашей сети, которые наверняка пришли Вам в голову:\n",
        "\n",
        "\n",
        "*   Учим дольше и изменяем гиперпараметры сети\n",
        "*  learning rate, batch size, нормализация картинки и вот это всё\n",
        "*   Кто же так строит нейронные сети? А где пулинги и батч нормы? Надо добавлять\n",
        "*  Ну разве Адам наше все? [adamW](https://www.fast.ai/2018/07/02/adam-weight-decay/) для практика, [статейка для любителей](https://openreview.net/pdf?id=ryQu7f-RZ) (очень хороший анализ), [наши ](https://github.com/MichaelKonobeev/adashift/) эксперименты для заинтересованных.\n",
        "\n",
        "* Ну разве это deep learning? Вот ResNet и Inception, которые можно зафайнтьюнить под наши данные, вот это я понимаю (можно и обучить в колабе, а можно и [готовые](https://github.com/Cadene/pretrained-models.pytorch) скачать).\n",
        "\n",
        "* Данных не очень много, можно их аугументировать и  доучититься на новом датасете ( который уже будет состоять из, как  пример аугументации, перевернутых изображений)\n",
        "\n",
        "* Стоит подумать об ансамблях\n",
        "\n",
        "\n",
        "Надеюсь, что у Вас получится!\n",
        "\n",
        "![alt text](https://pbs.twimg.com/profile_images/798904974986113024/adcQiVdV.jpg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hujX-faKhhw"
      },
      "outputs": [],
      "source": [
        "def new_fit_epoch(model, train_loader, criterion, optimizer):\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    processed_data = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs = inputs.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        preds = torch.argmax(outputs, 1)\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "        processed_data += inputs.size(0)\n",
        "\n",
        "    train_loss = running_loss / processed_data\n",
        "    train_acc = running_corrects.cpu().numpy() / processed_data\n",
        "    return train_loss, train_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQaJtqJrKoH9"
      },
      "outputs": [],
      "source": [
        "def new_eval_epoch(model, val_loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    processed_size = 0\n",
        "\n",
        "    for inputs, labels in val_loader:\n",
        "        inputs = inputs.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "\n",
        "        with torch.set_grad_enabled(False):\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            preds = torch.argmax(outputs, 1)\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "        processed_size += inputs.size(0)\n",
        "    val_loss = running_loss / processed_size\n",
        "    val_acc = running_corrects.double() / processed_size\n",
        "    return val_loss, val_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ukcJl_g78nK"
      },
      "outputs": [],
      "source": [
        "def train(train_files, val_files, model, epochs, batch_size):\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    history = []\n",
        "    log_template = \"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \\\n",
        "    val_loss {v_loss:0.4f} train_acc {t_acc:0.4f} val_acc {v_acc:0.4f}\"\n",
        "\n",
        "    with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:\n",
        "        opt = torch.optim.Adam(model.parameters(), lr=10e-5)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            train_loss, train_acc = fit_epoch(model, train_loader, criterion, opt)\n",
        "            print(\"loss\", train_loss)\n",
        "\n",
        "            val_loss, val_acc = eval_epoch(model, val_loader, criterion)\n",
        "            history.append((train_loss, train_acc, val_loss, val_acc))\n",
        "\n",
        "            pbar_outer.update(1)\n",
        "            tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss,\\\n",
        "                                           v_loss=val_loss, t_acc=train_acc, v_acc=val_acc))\n",
        "\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KFccpL_KR3x"
      },
      "outputs": [],
      "source": [
        "def mean_std(loader):\n",
        "  sum, squared_sum, num_batches = 0,0,0\n",
        "  for data,_ in loader:\n",
        "    sum += torch.mean(data,dim=[0,2,3])\n",
        "    squared_sum += torch.mean(data**2,dim=[0,2,3])\n",
        "    num_batches += 1\n",
        "  mean = sum/num_batches\n",
        "  std = (squared_sum/num_batches - mean**2)**0.5\n",
        "  return mean, std\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "mean, std = mean_std(train_loader)\n",
        "class experimental_dataset(Dataset):\n",
        "\n",
        "    def __init__(self, data, transform):\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data.shape[0])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        item = self.transform(item)\n",
        "        return item\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)\n",
        "])\n",
        "transformed_train_dataset = experimental_dataset(train_dataset, transform)\n",
        "transformed_val_dataset = experimental_dataset(val_dataset, transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vsa9BuVqKcBU"
      },
      "outputs": [],
      "source": [
        "class MyCnn(nn.Module):\n",
        "\n",
        "    def __init__(self, n_classes):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3),\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=96, kernel_size=3),\n",
        "            nn.BatchNorm2d(96),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "\n",
        "        self.out = nn.Linear(96 * 5 * 5, n_classes)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        logits = self.out(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIUI-eBe-vIE"
      },
      "outputs": [],
      "source": [
        "n_classes = len(np.unique(train_val_labels))\n",
        "my_cnn = MyCnn(n_classes).to(DEVICE)\n",
        "print(\"we will classify :{}\".format(n_classes))\n",
        "print(my_cnn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_1Sexia7Fxg"
      },
      "outputs": [],
      "source": [
        "n_classes = len(np.unique(train_val_labels))\n",
        "simple_cnn = SimpleCnn(n_classes).to(DEVICE)\n",
        "print(\"we will classify :{}\".format(n_classes))\n",
        "print(simple_cnn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBXsEEDfLBhs",
        "outputId": "6ea8fb50-ffd2-4132-b490-c3247c3dc1e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\repoch:   0%|          | 0/15 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.24532564686881456\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:   7%|▋         | 1/15 [02:15<31:39, 135.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 001 train_loss: 0.2453     val_loss 1.0653 train_acc 0.9324 val_acc 0.7585\n",
            "loss 0.18557372949986603\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  13%|█▎        | 2/15 [04:27<28:57, 133.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 002 train_loss: 0.1856     val_loss 1.0902 train_acc 0.9520 val_acc 0.7669\n",
            "loss 0.15206539563830396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  20%|██        | 3/15 [06:39<26:35, 132.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 003 train_loss: 0.1521     val_loss 1.1411 train_acc 0.9595 val_acc 0.7618\n",
            "loss 0.1180987897151002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  27%|██▋       | 4/15 [08:51<24:15, 132.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 004 train_loss: 0.1181     val_loss 1.1698 train_acc 0.9696 val_acc 0.7677\n",
            "loss 0.09280747724554024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  33%|███▎      | 5/15 [11:10<22:26, 134.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 005 train_loss: 0.0928     val_loss 1.2181 train_acc 0.9769 val_acc 0.7744\n",
            "loss 0.06993838221701333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  40%|████      | 6/15 [13:23<20:06, 134.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 006 train_loss: 0.0699     val_loss 1.2866 train_acc 0.9829 val_acc 0.7732\n",
            "loss 0.053229089143826416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  47%|████▋     | 7/15 [15:35<17:48, 133.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 007 train_loss: 0.0532     val_loss 1.3354 train_acc 0.9887 val_acc 0.7705\n",
            "loss 0.04658192249076789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  53%|█████▎    | 8/15 [17:48<15:33, 133.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 008 train_loss: 0.0466     val_loss 1.4118 train_acc 0.9902 val_acc 0.7715\n",
            "loss 0.054951797206201816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  60%|██████    | 9/15 [20:01<13:19, 133.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 009 train_loss: 0.0550     val_loss 1.4563 train_acc 0.9864 val_acc 0.7581\n",
            "loss 0.06955113600510246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  67%|██████▋   | 10/15 [22:15<11:06, 133.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 010 train_loss: 0.0696     val_loss 1.4511 train_acc 0.9806 val_acc 0.7612\n",
            "loss 0.025336556325850686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  73%|███████▎  | 11/15 [24:30<08:55, 133.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 011 train_loss: 0.0253     val_loss 1.4901 train_acc 0.9959 val_acc 0.7791\n",
            "loss 0.015981456488592765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  80%|████████  | 12/15 [26:45<06:42, 134.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 012 train_loss: 0.0160     val_loss 1.4929 train_acc 0.9981 val_acc 0.7801\n",
            "loss 0.03364443145040975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  87%|████████▋ | 13/15 [29:00<04:28, 134.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 013 train_loss: 0.0336     val_loss 1.4996 train_acc 0.9920 val_acc 0.7763\n",
            "loss 0.028523588903199427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  93%|█████████▎| 14/15 [31:15<02:14, 134.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 014 train_loss: 0.0285     val_loss 1.5660 train_acc 0.9941 val_acc 0.7715\n",
            "loss 0.03431296708358079\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch: 100%|██████████| 15/15 [33:28<00:00, 133.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 015 train_loss: 0.0343     val_loss 1.5708 train_acc 0.9921 val_acc 0.7719\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "history = train(transformed_train_dataset, transformed_val_dataset, model=my_cnn, epochs=15, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iglc8XJ1LcDh"
      },
      "outputs": [],
      "source": [
        "random_characters = int(np.random.uniform(0,1000))\n",
        "ex_img, true_label = val_dataset[random_characters]\n",
        "probs_im = predict_one_sample(my_cnn, ex_img.unsqueeze(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXwbe_MZLf8u"
      },
      "outputs": [],
      "source": [
        "idxs = list(map(int, np.random.uniform(0,1000, 20)))\n",
        "imgs = [val_dataset[id][0].unsqueeze(0) for id in idxs]\n",
        "\n",
        "probs_ims = predict(my_cnn, imgs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYPVIcmFLikt"
      },
      "outputs": [],
      "source": [
        "label_encoder = pickle.load(open(\"label_encoder.pkl\", 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27shJ0cDLiaw"
      },
      "outputs": [],
      "source": [
        "y_pred = np.argmax(probs_ims,-1)\n",
        "\n",
        "actual_labels = [val_dataset[id][1] for id in idxs]\n",
        "\n",
        "preds_class = [label_encoder.classes_[i] for i in y_pred]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJSA80e5LoP-",
        "outputId": "13a1c78e-9e3f-4b6f-e72e-c076cf0f1799"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-оценка: 0.75\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1 = f1_score(actual_labels, y_pred, average='micro')\n",
        "\n",
        "print(\"F1-оценка:\", f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NsBUdjegL46K"
      },
      "outputs": [],
      "source": [
        "test_dataset = SimpsonsDataset(test_files, mode=\"test\")\n",
        "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=64)\n",
        "probs = predict(my_cnn, test_loader)\n",
        "\n",
        "\n",
        "preds = label_encoder.inverse_transform(np.argmax(probs, axis=1))\n",
        "test_filenames = [path.name for path in test_dataset.files]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMtDdMCXL6XB",
        "outputId": "40c16dce-d8b8-415d-85eb-c8ee709965ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "characters_illustration.png  label_encoder.pkl\tsample_submission.csv\t testset\n",
            "gdrive\t\t\t     sample_data\tsimple_cnn_baseline.csv  train\n"
          ]
        }
      ],
      "source": [
        "! ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "nwWWcpdNL8qY",
        "outputId": "2ba6bdb9-b6c7-4bed-b088-b11c930cd364"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Id                Expected\n",
              "0    img0.jpg            nelson_muntz\n",
              "1    img1.jpg            bart_simpson\n",
              "2   img10.jpg            ned_flanders\n",
              "3  img100.jpg            chief_wiggum\n",
              "4  img101.jpg  apu_nahasapeemapetilon"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-babbb48e-ba45-409e-8e54-b2bba8b7a201\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Expected</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>img0.jpg</td>\n",
              "      <td>nelson_muntz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>img1.jpg</td>\n",
              "      <td>bart_simpson</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>img10.jpg</td>\n",
              "      <td>ned_flanders</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>img100.jpg</td>\n",
              "      <td>chief_wiggum</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>img101.jpg</td>\n",
              "      <td>apu_nahasapeemapetilon</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-babbb48e-ba45-409e-8e54-b2bba8b7a201')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-babbb48e-ba45-409e-8e54-b2bba8b7a201 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-babbb48e-ba45-409e-8e54-b2bba8b7a201');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-857e8c03-ed67-4a50-9f9f-cfa5524116f0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-857e8c03-ed67-4a50-9f9f-cfa5524116f0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-857e8c03-ed67-4a50-9f9f-cfa5524116f0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "import pandas as pd\n",
        "my_submit = pd.read_csv(\"/content/sample_submission.csv\")\n",
        "my_submit = pd.DataFrame({'Id': test_filenames, 'Expected': preds})\n",
        "my_submit.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doZ8rw4PMDxD"
      },
      "outputs": [],
      "source": [
        "my_submit.to_csv('my_cnn5_baseline.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}